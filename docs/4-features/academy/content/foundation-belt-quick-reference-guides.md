# CI Master Academy Foundation Belt - Quick Reference Guides

**Version:** 1.0  
**Created:** October 3, 2025  
**Purpose:** Practical, desk-ready reference cards for daily CI work  
**Format:** Designed for printing as laminated cards (8.5"√ó11" or 4"√ó6")

---

## How to Use These Guides

These quick reference guides are designed to be:
- **Printed and laminated** for desk/workstation display
- **Saved as PDFs** for digital quick access
- **Shared with team members** learning CI
- **Used during improvement projects** as job aids

**Print Instructions:**
- Each guide formatted for standard letter size (8.5"√ó11")
- Can be scaled to 4"√ó6" cards for pocket reference
- Recommend lamination for durability
- Color printing enhances usability

---

# GUIDE 1: The 8 Wastes (DOWNTIME) Identification Card

**Purpose:** Quickly identify waste in any process  
**Use:** During Gemba walks, process observations, VSM sessions

---

## THE 8 WASTES (DOWNTIME)

### üî¥ **D - DEFECTS**
**Definition:** Products or services that don't meet requirements  
**Examples:**
- Errors requiring rework
- Scrap or rejected items
- Customer returns
- Incorrect information

**Questions to Ask:**
- What's our defect/error rate?
- Where do defects occur most?
- What's the cost of fixing defects?

**Impact:** Quality issues, customer dissatisfaction, rework costs

---

### üî¥ **O - OVERPRODUCTION**
**Definition:** Producing more, sooner, or faster than needed  
**Examples:**
- Making items before orders received
- Producing ahead of schedule
- Creating reports no one reads
- Batch processing beyond demand

**Questions to Ask:**
- Are we making more than customers need?
- Is inventory building up?
- Do we produce "just in case"?

**Impact:** Excess inventory, storage costs, obsolescence, hides problems

---

### üî¥ **W - WAITING**
**Definition:** Idle time when work is not progressing  
**Examples:**
- Waiting for approvals
- Equipment downtime
- System processing delays
- Waiting for materials/information

**Questions to Ask:**
- How much time is spent waiting vs. working?
- What causes the most delays?
- Can we overlap activities?

**Impact:** Extended lead times, reduced capacity, employee frustration

---

### üî¥ **N - NON-UTILIZED TALENT**
**Definition:** Not fully using people's skills, knowledge, and abilities  
**Examples:**
- No involvement in improvement
- Micromanagement limiting autonomy
- Assigning overqualified people to simple tasks
- Not listening to employee ideas

**Questions to Ask:**
- Are employees empowered to improve?
- Do we tap into frontline knowledge?
- Are people working below their capability?

**Impact:** Low engagement, turnover, missed improvement opportunities

---

### üî¥ **T - TRANSPORTATION**
**Definition:** Unnecessary movement of materials, products, or information  
**Examples:**
- Excessive distances between steps
- Multiple handoffs
- Poor layout design
- Centralized storage far from use point

**Questions to Ask:**
- How far do materials travel?
- Can we reduce handoffs?
- Is layout optimized?

**Impact:** Damage risk, time delays, handling costs

---

### üî¥ **I - INVENTORY**
**Definition:** Excess raw materials, WIP, or finished goods beyond minimum needed  
**Examples:**
- Stockpiling materials
- Work piling up between steps
- Finished goods awaiting shipment
- Obsolete stock

**Questions to Ask:**
- How much inventory do we really need?
- What's hidden by excess inventory?
- Can we move to pull system?

**Impact:** Tied-up capital, storage costs, obsolescence, hides problems

---

### üî¥ **M - MOTION**
**Definition:** Unnecessary human movement or ergonomic strain  
**Examples:**
- Searching for tools/materials
- Excessive reaching, bending, walking
- Poor workstation layout
- Switching between systems

**Questions to Ask:**
- Do people have everything within reach?
- Is workspace ergonomically designed?
- How much time searching for things?

**Impact:** Fatigue, safety risks, reduced productivity, injury

---

### üî¥ **E - EXCESS PROCESSING**
**Definition:** Doing more work than customer requires or values  
**Examples:**
- Over-engineering products
- Redundant approvals
- Excessive paperwork
- Re-entering data

**Questions to Ask:**
- Does the customer care about this step?
- Are we adding unnecessary features?
- Can we simplify the process?

**Impact:** Wasted time, unnecessary costs, complexity

---

## WASTE HUNTING CHECKLIST

**During process observation, ask:**

‚ñ° Are we making defects?  
‚ñ° Are we producing more than needed?  
‚ñ° Is anyone or anything waiting?  
‚ñ° Are we fully using people's talents?  
‚ñ° Are things moving unnecessarily?  
‚ñ° Is inventory piling up?  
‚ñ° Are people moving excessively?  
‚ñ° Are we doing unnecessary work?

**Remember:** Every process has waste. The goal is to continuously reduce it!

**Next Step:** Quantify the waste (time, cost, frequency) to prioritize improvements.

---

# GUIDE 2: DMAIC Quick Reference

**Purpose:** Navigate Six Sigma projects systematically  
**Use:** During DMAIC projects, team meetings, project planning

---

## DMAIC FRAMEWORK OVERVIEW

**D** - Define ‚Üí **M** - Measure ‚Üí **A** - Analyze ‚Üí **I** - Improve ‚Üí **C** - Control

**Timeline:** Typically 4-6 months  
**Team:** Cross-functional (Black/Green Belt, SMEs, stakeholders)

---

## üìã **DEFINE PHASE** (Weeks 1-2)

### Purpose
Clearly articulate problem, establish goals, secure resources

### Key Activities
- ‚úì Write problem statement (What + Where + When + Impact)
- ‚úì Create SMART goal statement
- ‚úì Define scope (In/Out)
- ‚úì Build business case (cost of problem, expected benefit, ROI)
- ‚úì Identify stakeholders and engage early
- ‚úì Assign team roles (Sponsor, Champion, Belt, Team Members)
- ‚úì Create high-level SIPOC diagram
- ‚úì Capture Voice of Customer (VOC)
- ‚úì Translate VOC to CTQ requirements

### Key Deliverable
**Project Charter** (one-page document with all above elements)

### Success Criteria
- Clear, specific problem statement
- SMART goal with measurable target
- Stakeholder buy-in and sponsor approval
- Charter signed off

### Common Mistakes to Avoid
‚ùå Vague problem statement  
‚ùå Solution stated as problem  
‚ùå Scope too broad  
‚ùå Skipping stakeholder analysis

---

## üìä **MEASURE PHASE** (Weeks 3-6)

### Purpose
Establish baseline performance and validate measurement system

### Key Activities
- ‚úì Create operational definitions (precise, measurable)
- ‚úì Conduct Gage R&R study (MSA) - target <30%
- ‚úì Develop data collection plan (What, How, Where, When, Who)
- ‚úì Collect baseline data (minimum 30 data points, prefer 100+)
- ‚úì Calculate descriptive statistics (mean, std dev, range)
- ‚úì Create histogram to visualize distribution
- ‚úì Calculate process capability (Cp, Cpk)
- ‚úì Stratify data by suspected factors
- ‚úì Identify measurement gaps

### Key Deliverables
- Validated measurement system
- Baseline performance data
- Process capability assessment (Cp/Cpk)
- Data visualizations

### Success Criteria
- Gage R&R <30% (measurement system acceptable)
- Sufficient data collected (n ‚â• 30)
- Baseline clearly quantified
- Improvement opportunity sized

### Common Mistakes to Avoid
‚ùå Skipping operational definitions  
‚ùå Not validating measurement system  
‚ùå Too little data collected  
‚ùå No stratification

---

## üîç **ANALYZE PHASE** (Weeks 7-10)

### Purpose
Identify and verify root causes with data

### Key Activities
- ‚úì Brainstorm potential causes (Fishbone diagram, 6 M's)
- ‚úì Use Pareto analysis to prioritize causes (80/20 rule)
- ‚úì Stratify data by suspected causes
- ‚úì Create scatter plots (test correlation)
- ‚úì Apply 5 Whys to drill to root causes
- ‚úì Use hypothesis testing (t-test, ANOVA, Chi-square)
- ‚úì Verify root causes with data (p-value < 0.05)
- ‚úì Quantify impact of each root cause
- ‚úì Get team consensus on root causes

### Key Deliverables
- Fishbone diagram with potential causes
- Pareto chart showing vital few causes
- Statistical analysis results
- Verified root causes (top 2-3)

### Success Criteria
- Root causes verified with data (not opinions)
- Statistical significance demonstrated
- Team agrees on root causes
- Causes are actionable

### Common Mistakes to Avoid
‚ùå Jumping to solutions without analysis  
‚ùå Blaming people instead of systems  
‚ùå No data to verify causes  
‚ùå Stopping at symptoms, not root causes

---

## üí° **IMPROVE PHASE** (Weeks 11-18)

### Purpose
Develop, test, and implement solutions

### Key Activities
- ‚úì Brainstorm solutions for each root cause
- ‚úì Use SCAMPER, brainstorming techniques
- ‚úì Evaluate solutions (Impact/Effort Matrix)
- ‚úì Select top solutions (prioritize Quick Wins)
- ‚úì Design pilot test (small scale, limited scope)
- ‚úì Create implementation plan (What, Why, Who, When, Where, How)
- ‚úì Communicate change to stakeholders
- ‚úì Train affected staff
- ‚úì Run pilot and collect data
- ‚úì Refine solution based on pilot results
- ‚úì Implement full-scale if pilot successful
- ‚úì Measure results (compare to baseline)

### Key Deliverables
- List of potential solutions
- Solution selection matrix
- Pilot test plan and results
- Implementation plan
- Before/after comparison

### Success Criteria
- Solutions address verified root causes
- Pilot demonstrates improvement
- Full implementation successful
- Goal achieved (SMART target met)

### Common Mistakes to Avoid
‚ùå No pilot test (implement full-scale immediately)  
‚ùå Poor communication/change management  
‚ùå Insufficient training  
‚ùå Declaring victory too early

---

## üîí **CONTROL PHASE** (Weeks 19-20)

### Purpose
Sustain improvements over time

### Key Activities
- ‚úì Create Control Plan (what to monitor, limits, actions)
- ‚úì Implement control charts (SPC) to monitor key metrics
- ‚úì Document new standard procedures (SOPs)
- ‚úì Train all staff on new standards
- ‚úì Make standards visible (visual management)
- ‚úì Build controls into systems (poka-yoke, checklists)
- ‚úì Set up regular review cadence
- ‚úì Hand off to process owner
- ‚úì Create final project report
- ‚úì Celebrate and recognize team
- ‚úì Document lessons learned

### Key Deliverables
- Control plan
- Updated SOPs
- Control charts
- Training materials
- Final project report

### Success Criteria
- Improvements sustained for 3+ months
- Process owner accepts responsibility
- Standards documented and visible
- Monitoring system in place

### Common Mistakes to Avoid
‚ùå No formal handoff to process owner  
‚ùå Standards not documented  
‚ùå No ongoing monitoring  
‚ùå Declaring project "done" prematurely

---

## PROJECT HEALTH CHECK

**Use this checklist to ensure project stays on track:**

### Define
‚ñ° Problem statement is specific and quantified  
‚ñ° Goal is SMART  
‚ñ° Stakeholders identified and engaged  
‚ñ° Charter approved by sponsor

### Measure
‚ñ° Measurement system validated (Gage R&R)  
‚ñ° Baseline data collected (n ‚â• 30)  
‚ñ° Process capability calculated  
‚ñ° Improvement opportunity quantified

### Analyze
‚ñ° Multiple techniques used (Fishbone, Pareto, 5 Whys)  
‚ñ° Root causes verified with data  
‚ñ° Statistical significance demonstrated  
‚ñ° Team consensus achieved

### Improve
‚ñ° Solutions piloted before full implementation  
‚ñ° Change management addressed  
‚ñ° Staff trained on new methods  
‚ñ° Results measured and compared to baseline

### Control
‚ñ° Control plan created and implemented  
‚ñ° Standards documented  
‚ñ° Process owner trained and committed  
‚ñ° Monitoring system established

---

# GUIDE 3: Statistical Formulas Cheat Sheet

**Purpose:** Quick reference for common CI calculations  
**Use:** During data analysis, Measure/Analyze phases, capability studies

---

## DESCRIPTIVE STATISTICS

### **Mean (Average)**
```
xÃÑ = (Œ£x) √∑ n
```
- **Œ£x** = Sum of all data points
- **n** = Number of data points
- **Use:** Measure of central tendency
- **Example:** (10+12+14+16+18) √∑ 5 = 14

---

### **Median**
```
Middle value when data is ordered
```
- **Even n:** Average of two middle values
- **Odd n:** Middle value
- **Use:** Central tendency less affected by outliers
- **Example:** 10, 12, **14**, 16, 18 ‚Üí Median = 14

---

### **Mode**
```
Most frequently occurring value
```
- **Use:** Identify most common value
- **Note:** Dataset can have multiple modes or no mode

---

### **Range**
```
Range = Maximum - Minimum
```
- **Use:** Simple measure of spread
- **Example:** Max=18, Min=10 ‚Üí Range = 8

---

### **Standard Deviation (Sample)**
```
s = ‚àö[Œ£(x - xÃÑ)¬≤ √∑ (n-1)]
```
- **s** = Sample standard deviation
- **x** = Individual data point
- **xÃÑ** = Sample mean
- **n** = Sample size
- **Use:** Measure of variation around mean
- **Note:** Population SD uses n instead of n-1

---

### **Variance**
```
s¬≤ = Œ£(x - xÃÑ)¬≤ √∑ (n-1)
```
- **Use:** Standard deviation squared
- **Note:** Same units¬≤ as data (harder to interpret)

---

### **Coefficient of Variation (CV)**
```
CV = (s √∑ xÃÑ) √ó 100%
```
- **Use:** Compare variation across different scales
- **Expressed as:** Percentage
- **Example:** s=2, xÃÑ=50 ‚Üí CV = 4%

---

## PROCESS CAPABILITY

### **Cp (Process Capability - Potential)**
```
Cp = (USL - LSL) √∑ (6œÉ)
```
- **USL** = Upper Specification Limit
- **LSL** = Lower Specification Limit
- **œÉ** = Standard deviation
- **Interpretation:**
  - Cp ‚â• 1.33 = Capable
  - Cp = 1.00 = Barely capable
  - Cp < 1.00 = Not capable
- **Note:** Assumes process is centered

---

### **Cpk (Process Capability - Actual)**
```
Cpk = min[Cpu, Cpl]

Where:
Cpu = (USL - xÃÑ) √∑ (3œÉ)
Cpl = (xÃÑ - LSL) √∑ (3œÉ)
```
- **xÃÑ** = Process mean
- **Interpretation:**
  - Cpk ‚â• 1.33 = Capable
  - Cpk = 1.00 = Barely capable
  - Cpk < 1.00 = Not capable
- **Note:** Accounts for process centering

---

### **Sigma Level**
```
Sigma Level ‚âà (Cpk √ó 3) + 1.5

Or use DPMO table:
3œÉ = 66,807 DPMO
4œÉ = 6,210 DPMO
5œÉ = 233 DPMO
6œÉ = 3.4 DPMO
```

---

### **DPMO (Defects Per Million Opportunities)**
```
DPMO = (Defects √∑ Opportunities) √ó 1,000,000
```
- **Example:** 50 defects in 10,000 opportunities
  - DPMO = (50 √∑ 10,000) √ó 1,000,000 = 5,000 DPMO
  - This ‚âà 4 sigma level

---

## LEAN METRICS

### **Takt Time**
```
Takt Time = Available Work Time √∑ Customer Demand
```
- **Example:** 480 min available, 240 units needed
  - Takt = 480 √∑ 240 = 2 minutes per unit
- **Use:** Set production pace to match demand

---

### **Cycle Time**
```
Cycle Time = Total Process Time (including delays)
```
- **Measured:** Minutes, hours, days
- **Goal:** Reduce to approach Takt Time

---

### **Lead Time**
```
Lead Time = Time from customer request to delivery
```
- **Customer perspective:** Includes all wait times
- **Goal:** Minimize while maintaining quality

---

### **Process Cycle Efficiency (PCE)**
```
PCE = (Value-Added Time √∑ Total Lead Time) √ó 100%
```
- **Example:** 2 hours VA time, 40 hours lead time
  - PCE = (2 √∑ 40) √ó 100% = 5%
- **Typical:** 5-10% in most processes
- **World-class:** >25%

---

### **Little's Law**
```
Lead Time = WIP √∑ Throughput
```
- **WIP** = Work-in-Process inventory
- **Throughput** = Rate of completion
- **Use:** Understand relationship between WIP and lead time

---

### **Overall Equipment Effectiveness (OEE)**
```
OEE = Availability √ó Performance √ó Quality

Where:
Availability = (Operating Time √∑ Planned Time)
Performance = (Actual Output √∑ Theoretical Output)
Quality = (Good Units √∑ Total Units)
```
- **World-class OEE:** >85%
- **Example:** 0.90 √ó 0.95 √ó 0.98 = 0.84 (84% OEE)

---

## STATISTICAL TESTS

### **Z-Score**
```
Z = (x - Œº) √∑ œÉ
```
- **Use:** How many standard deviations from mean
- **Example:** x=120, Œº=100, œÉ=10 ‚Üí Z = 2.0

---

### **Empirical Rule (Normal Distribution)**
```
¬±1œÉ = 68% of data
¬±2œÉ = 95% of data
¬±3œÉ = 99.7% of data
```

---

### **Sample Size (for proportion)**
```
n = (Z¬≤ √ó p √ó (1-p)) √∑ E¬≤
```
- **Z** = Z-score for confidence level (1.96 for 95%)
- **p** = Expected proportion (use 0.5 if unknown)
- **E** = Margin of error
- **Example:** 95% confidence, ¬±5% error
  - n = (1.96¬≤ √ó 0.5 √ó 0.5) √∑ 0.05¬≤ = 384

---

## CONTROL CHARTS

### **Control Limits (Individual-X Chart)**
```
Center Line (CL) = xÃÑ

UCL = xÃÑ + 3œÉ
LCL = xÃÑ - 3œÉ
```
- **UCL** = Upper Control Limit
- **LCL** = Lower Control Limit

---

### **Control Limits (X-bar Chart)**
```
UCL = xÃÑ + A‚ÇÇ √ó RÃÑ
LCL = xÃÑ - A‚ÇÇ √ó RÃÑ
```
- **A‚ÇÇ** = Constant based on subgroup size (from table)
- **RÃÑ** = Average range

---

## QUICK CALCULATION TIPS

**Estimating Standard Deviation:**
```
œÉ ‚âà Range √∑ 4 (for n=30)
œÉ ‚âà Range √∑ 5 (for n=100)
```

**Estimating Sigma Level from Defect Rate:**
- 1% defects ‚âà 2.7œÉ
- 0.1% defects ‚âà 3.8œÉ
- 0.01% defects ‚âà 4.8œÉ
- 0.001% defects ‚âà 5.8œÉ

**Converting between metrics:**
```
PPM = (Defect Rate) √ó 1,000,000
Yield = 1 - Defect Rate
```

---

# GUIDE 4: Lean Tools Selection Matrix

**Purpose:** Choose the right Lean tool for your situation  
**Use:** Project planning, tool selection, team discussions

---

## TOOL SELECTION MATRIX

### **PROBLEM: High Inventory / Long Lead Times**

| Tool | Best For | Time to Implement | Difficulty | Impact |
|------|----------|-------------------|------------|--------|
| **Value Stream Mapping** | Understanding entire flow, identifying bottlenecks | 1-2 weeks | Medium | High |
| **Kanban/Pull System** | Controlling WIP, preventing overproduction | 2-4 weeks | Medium | High |
| **5S** | Organizing workspace, reducing search time | 1-2 weeks | Low | Medium |
| **Heijunka (Leveling)** | Smoothing demand variability | 4-8 weeks | High | High |

**Recommended Starting Point:** Value Stream Mapping (identify where inventory accumulates)

---

### **PROBLEM: Quality Issues / Defects**

| Tool | Best For | Time to Implement | Difficulty | Impact |
|------|----------|-------------------|------------|--------|
| **Poka-Yoke** | Preventing specific errors | 1-2 weeks | Low-Medium | High |
| **5 Whys** | Finding root causes quickly | 1-2 days | Low | Medium |
| **Andon System** | Stopping problems immediately | 2-4 weeks | Medium | High |
| **Jidoka** | Building quality into process | 4-12 weeks | High | Very High |
| **Standard Work** | Ensuring consistency | 2-4 weeks | Medium | High |

**Recommended Starting Point:** 5 Whys (understand root causes) ‚Üí Poka-Yoke (prevent recurrence)

---

### **PROBLEM: Excessive Motion / Poor Layout**

| Tool | Best For | Time to Implement | Difficulty | Impact |
|------|----------|-------------------|------------|--------|
| **Spaghetti Diagram** | Visualizing current movement | 1 day | Low | Medium |
| **5S** | Organizing workspace | 1-2 weeks | Low | Medium |
| **Work Cell Design** | Optimizing layout for flow | 2-4 weeks | Medium | High |
| **Standard Work** | Minimizing unnecessary movement | 2-4 weeks | Medium | Medium |

**Recommended Starting Point:** Spaghetti Diagram ‚Üí 5S ‚Üí Layout redesign

---

### **PROBLEM: Inconsistent Processes / High Variation**

| Tool | Best For | Time to Implement | Difficulty | Impact |
|------|----------|-------------------|------------|--------|
| **Standard Work** | Creating consistency | 2-4 weeks | Medium | High |
| **Training Within Industry (TWI)** | Training to standard | 4-8 weeks | Medium | High |
| **Visual Management** | Making standards visible | 1-2 weeks | Low | Medium |
| **5S** | Organizing for standardization | 1-2 weeks | Low | Medium |

**Recommended Starting Point:** Standard Work ‚Üí Visual Management ‚Üí Training

---

### **PROBLEM: Equipment Downtime / Breakdowns**

| Tool | Best For | Time to Implement | Difficulty | Impact |
|------|----------|-------------------|------------|--------|
| **TPM (Total Productive Maintenance)** | Comprehensive equipment care | 12+ weeks | High | Very High |
| **5S** | Basic equipment care | 1-2 weeks | Low | Medium |
| **OEE Tracking** | Measuring equipment effectiveness | 2-4 weeks | Low | Medium |
| **Preventive Maintenance** | Scheduled maintenance | 4-8 weeks | Medium | High |

**Recommended Starting Point:** OEE Tracking (measure current state) ‚Üí 5S ‚Üí PM Schedule

---

### **PROBLEM: Complex Processes / Unclear Flow**

| Tool | Best For | Time to Implement | Difficulty | Impact |
|------|----------|-------------------|------------|--------|
| **Process Mapping** | Understanding current process | 1-2 days | Low | Medium |
| **Value Stream Mapping** | End-to-end view with metrics | 1-2 weeks | Medium | High |
| **SIPOC** | High-level process view | 1-2 hours | Very Low | Low |
| **Swimlane Diagram** | Clarifying roles/handoffs | 1-2 days | Low | Medium |

**Recommended Starting Point:** SIPOC (high level) ‚Üí Process Mapping ‚Üí VSM (detailed)

---

## TOOL CHARACTERISTICS

### **QUICK WINS (Implement First)**
- ‚úÖ **5S** - Low difficulty, visible results, builds momentum
- ‚úÖ **Visual Management** - Easy to implement, immediate clarity
- ‚úÖ **5 Whys** - Simple technique, powerful insights
- ‚úÖ **Process Mapping** - Reveals problems quickly

**Timeline:** Days to weeks  
**Resources:** Minimal  
**Risk:** Low

---

### **MEDIUM COMPLEXITY (After Quick Wins)**
- ‚è∫Ô∏è **Standard Work** - Requires documentation and training
- ‚è∫Ô∏è **Kanban** - Needs pull system understanding
- ‚è∫Ô∏è **Value Stream Mapping** - Requires data collection
- ‚è∫Ô∏è **Poka-Yoke** - Needs creative problem-solving

**Timeline:** Weeks to months  
**Resources:** Moderate  
**Risk:** Low-Medium

---

### **ADVANCED (Requires Infrastructure)**
- üî∫ **TPM** - Comprehensive, long-term commitment
- üî∫ **Heijunka** - Requires production flexibility
- üî∫ **Jidoka** - May require automation investment
- üî∫ **One-Piece Flow** - Significant process redesign

**Timeline:** Months to years  
**Resources:** Significant  
**Risk:** Medium-High

---

## TOOL COMBINATION STRATEGIES

### **Strategy 1: Foundation First**
1. Start with 5S (organize workspace)
2. Add Visual Management (make status visible)
3. Implement Standard Work (create consistency)
4. Result: Stable foundation for advanced tools

---

### **Strategy 2: Flow Focus**
1. Value Stream Map (identify bottlenecks)
2. Implement Kanban (control WIP)
3. Balance workload (takt time analysis)
4. Result: Improved flow and reduced lead time

---

### **Strategy 3: Quality Focus**
1. Use 5 Whys (find root causes)
2. Implement Poka-Yoke (prevent errors)
3. Add Andon (stop on defect)
4. Result: Built-in quality

---

## DECISION TREE

```
START ‚Üí What's your primary concern?

‚îú‚îÄ SPEED/FLOW?
‚îÇ  ‚îú‚îÄ Know where problems are? NO ‚Üí Value Stream Mapping
‚îÇ  ‚îî‚îÄ Know where problems are? YES ‚Üí Kanban/Pull System
‚îÇ
‚îú‚îÄ QUALITY?
‚îÇ  ‚îú‚îÄ Know root cause? NO ‚Üí 5 Whys
‚îÇ  ‚îî‚îÄ Know root cause? YES ‚Üí Poka-Yoke
‚îÇ
‚îú‚îÄ ORGANIZATION?
‚îÇ  ‚îî‚îÄ Always start with ‚Üí 5S
‚îÇ
‚îú‚îÄ COST?
‚îÇ  ‚îú‚îÄ Identify waste ‚Üí Value Stream Mapping
‚îÇ  ‚îî‚îÄ Then eliminate based on type (see 8 Wastes)
‚îÇ
‚îî‚îÄ NOT SURE?
   ‚îî‚îÄ Start with ‚Üí Process Mapping or SIPOC
```

---

## TOOL READINESS CHECKLIST

**Before implementing any tool, ensure:**

‚ñ° Leadership support secured  
‚ñ° Team trained on tool basics  
‚ñ° Pilot area selected (don't implement everywhere at once)  
‚ñ° Success metrics defined  
‚ñ° Resources allocated  
‚ñ° Timeline realistic  
‚ñ° Communication plan created

**Remember:** Perfect implementation of simple tool beats poor implementation of complex tool!

---

# GUIDE 5: Root Cause Analysis Toolkit

**Purpose:** Systematic approach to finding and verifying root causes  
**Use:** During problem-solving, Analyze phase, incident investigations

---

## RCA PROCESS OVERVIEW

**Step 1:** Define the problem clearly (specific, measurable)  
**Step 2:** Brainstorm potential causes (generate many)  
**Step 3:** Use data to narrow causes (test with data)  
**Step 4:** Drill to root causes (ask "why" repeatedly)  
**Step 5:** Verify root causes (statistical tests)  
**Step 6:** Prioritize (focus on vital few)

**Timeline:** 1-4 weeks depending on complexity

---

## TOOL 1: FISHBONE DIAGRAM (ISHIKAWA)

### When to Use
- Brainstorming many potential causes
- Organizing causes by category
- Team-based problem-solving
- Visual representation needed

### How to Create

**Step 1:** Draw problem as "fish head" on right  
**Step 2:** Draw main "bones" - 6 categories:
- **M**ethods (procedures, processes)
- **M**achines (equipment, technology)
- **M**aterials (inputs, supplies)
- **M**easurements (how we measure)
- **M**other Nature (environment, conditions)
- **M**anpower / People (training, skills)

**Step 3:** Team brainstorms causes for each category  
**Step 4:** Ask "Why?" for each cause to go deeper  
**Step 5:** Circle most likely causes for data verification

### Example Structure
```
    Methods          Machines
      |                 |
      |                 |
   ----\             /----
        \           /
         \         /
    ------PROBLEM------
         /         \
        /           \
   ----/             \----
      |                 |
      |                 |
   Materials       Measurements
      
   (Add Mother Nature and Manpower below)
```

### Pro Tips
- Generate 30-50 potential causes (quantity over quality initially)
- No criticism during brainstorming
- Involve people who do the work
- Use data to verify causes after brainstorming

---

## TOOL 2: 5 WHYS

### When to Use
- Drilling from symptoms to root causes
- Quick RCA (minutes to hours)
- Single-stream problems
- Building on Fishbone results

### How to Use

**Start with problem ‚Üí Ask "Why?" ‚Üí Answer ‚Üí Ask "Why?" again ‚Üí Repeat ~5 times**

**Example:**

**Problem:** Customer shipment was late

**Why #1:** Why was shipment late?  
**Answer:** Warehouse didn't process order in time

**Why #2:** Why didn't warehouse process in time?  
**Answer:** They were understaffed that day

**Why #3:** Why understaffed?  
**Answer:** Two employees called in sick

**Why #4:** Why did both calling in cause delay?  
**Answer:** No cross-training backup plan exists

**Why #5:** Why no backup plan?  
**Answer:** No formal process for ensuring redundancy

**ROOT CAUSE:** Lack of formal redundancy planning process

**Solution:** Create cross-training program and backup staffing protocols

### How to Know You've Reached Root Cause

‚úì Fixing this will prevent recurrence  
‚úì Cause is actionable (within your control)  
‚úì Cause is a system/process issue (not blaming person)  
‚úì Can't meaningfully ask "why" again

### Common Mistakes

‚ùå Stopping too early (symptoms, not root causes)  
‚ùå Blaming people ("operator error") instead of systems  
‚ùå Guessing instead of verifying with data  
‚ùå Going down wrong path

### Pro Tips
- Use data to verify each "why"
- May need fewer or more than 5 whys
- Focus on systems, not people
- Document your logic

---

## TOOL 3: PARETO ANALYSIS

### When to Use
- Prioritizing causes by impact
- Focusing on "vital few" vs. "trivial many"
- Data is available for causes
- Need to allocate limited resources

### 80/20 Rule
**80% of problems typically come from 20% of causes**

### How to Create Pareto Chart

**Step 1:** List all causes with frequency/impact data  
**Step 2:** Sort from highest to lowest  
**Step 3:** Calculate cumulative percentage  
**Step 4:** Create bar chart (sorted) with cumulative line  
**Step 5:** Identify causes in "vital few" (usually 2-3 causes causing 80%)

### Example

| Cause | Count | % | Cumulative % |
|-------|-------|---|--------------|
| Cause A | 45 | 45% | 45% |
| Cause B | 28 | 28% | 73% |
| Cause C | 15 | 15% | 88% |
| Cause D | 8 | 8% | 96% |
| Other | 4 | 4% | 100% |

**Insight:** Causes A & B account for 73% of problem ‚Üí Focus here!

### Pro Tips
- Always include "Other" category
- Can apply Pareto to Pareto (drill down on Cause A)
- Update as you eliminate top causes
- Combine with stratification for deeper insights

---

## TOOL 4: STRATIFICATION

### When to Use
- Patterns hidden in aggregate data
- Suspected cause needs verification
- Available subgroup data
- Want to see detailed breakdown

### Common Stratification Factors
- Time (shift, day of week, season)
- Location (plant, line, workstation)
- People (operator, team, department)
- Equipment (machine, tool, model)
- Material (lot, supplier, batch)
- Method (procedure version, training level)

### Example

**Aggregate:** Overall defect rate = 5%

**Stratified by Shift:**
- Shift A: 2% ‚ùå
- Shift B: 3% ‚ùå
- Shift C: 10% ‚úÖ **CAUSE IDENTIFIED!**

**Conclusion:** Problem is shift-specific ‚Üí Investigate Shift C processes, training, supervision

### Pro Tips
- Stratify by multiple factors simultaneously
- Use visuals (separate histograms, box plots)
- Look for factors with largest differences
- Verify significance with statistical tests

---

## TOOL 5: SCATTER PLOTS (CORRELATION ANALYSIS)

### When to Use
- Testing if two variables are related
- Visualizing potential cause-effect relationship
- Continuous data available
- Want quick visual analysis

### How to Create
- X-axis: Suspected cause (independent variable)
- Y-axis: Problem metric (dependent variable)
- Plot each data point
- Look for pattern

### Patterns & Interpretation

**Positive Correlation:** As X increases, Y increases  
‚Üí Possible cause relationship

**Negative Correlation:** As X increases, Y decreases  
‚Üí Possible inverse cause relationship

**No Correlation:** Random scatter  
‚Üí Not related (not a cause)

### Example
- X-axis: Temperature (¬∞F)
- Y-axis: Defect rate (%)
- Pattern: Upward trend
- **Conclusion:** Temperature appears to cause defects ‚Üí Verify with test

### Important Caution
**Correlation does NOT prove causation!**
- Always verify with additional analysis
- Consider confounding variables
- Use hypothesis testing for statistical proof

---

## TOOL 6: HYPOTHESIS TESTING

### When to Use
- Verifying if differences are real vs. random chance
- Providing statistical proof of cause
- Comparing groups or time periods
- Supporting RCA with statistics

### Common Tests

**Comparing Two Means:**
- **t-test** (e.g., Shift A vs. Shift B defect rates)

**Comparing 3+ Means:**
- **ANOVA** (e.g., All shifts, all machines)

**Comparing Proportions:**
- **Chi-square** (e.g., Pass/fail rates by department)

**Testing Correlation:**
- **Regression** (e.g., Temperature impact on yield)

### Interpretation

**p-value < 0.05:** Statistically significant (cause verified!)  
**p-value ‚â• 0.05:** Not statistically significant (may not be cause)

### Example
**Hypothesis:** Machine A has higher defect rate than Machine B

**Data:**
- Machine A: 8% defects
- Machine B: 5% defects

**Test:** 2-sample t-test  
**Result:** p-value = 0.02

**Conclusion:** p < 0.05 ‚Üí Difference is statistically significant ‚Üí Machine A IS a cause

### Pro Tips
- Let software do calculations (Minitab, Excel, JMP)
- Understand which test to use (ask statistician if unsure)
- Statistical significance ‚â† practical significance
- Always interpret in context

---

## RCA WORKFLOW

```
START ‚Üí Define Problem (specific, measurable)
  ‚Üì
Brainstorm Causes (Fishbone with team)
  ‚Üì
Collect Data (on potential causes)
  ‚Üì
Prioritize Causes (Pareto analysis)
  ‚Üì
Stratify Data (by suspected factors)
  ‚Üì
Test Correlation (Scatter plots)
  ‚Üì
Drill to Root (5 Whys on top causes)
  ‚Üì
Verify Statistically (Hypothesis testing)
  ‚Üì
Document Root Causes (top 2-3 verified)
  ‚Üì
Develop Solutions ‚Üí Implement ‚Üí Control
```

**Timeline:** 1-4 weeks depending on complexity

---

## ROOT CAUSE VALIDATION CHECKLIST

**Before claiming you've found root cause, verify:**

‚ñ° Verified with data (not assumptions)  
‚ñ° Statistically significant (if tested)  
‚ñ° Fixing it will prevent recurrence (not just this instance)  
‚ñ° Actionable (within control to fix)  
‚ñ° System/process issue (not blaming people)  
‚ñ° Team consensus achieved  
‚ñ° Can explain cause-effect mechanism  
‚ñ° Documented with evidence

**Warning Signs You Haven't Found Root Cause:**
‚ö†Ô∏è "Operator error" or "human error" (go deeper!)  
‚ö†Ô∏è Vague cause (not specific enough to act on)  
‚ö†Ô∏è No data supporting the cause  
‚ö†Ô∏è Can't explain how cause creates problem

---

## COMMON RCA MISTAKES

### Mistake 1: Jumping to Solutions
‚ùå **Wrong:** "We need new equipment" (that's a solution!)  
‚úÖ **Right:** "Equipment downtime causes delays" (that's a problem to analyze)

### Mistake 2: Blaming People
‚ùå **Wrong:** "John made a mistake"  
‚úÖ **Right:** "No verification step exists to catch errors"

### Mistake 3: Stopping at Symptoms
‚ùå **Wrong:** "Part failed"  
‚úÖ **Right:** "Part failed because no preventive maintenance system exists"

### Mistake 4: No Data Verification
‚ùå **Wrong:** "We think it's the temperature"  
‚úÖ **Right:** "Data shows defects spike when temp >75¬∞F (p=0.001)"

### Mistake 5: Too Many Root Causes
‚ùå **Wrong:** Identifying 15 root causes  
‚úÖ **Right:** Focus on vital few (2-3 causes creating 80% of problem)

---

# GUIDE 6: Process Mapping Symbols & Conventions

**Purpose:** Create clear, consistent process maps  
**Use:** Process mapping, VSM, documentation, team workshops

---

## STANDARD FLOWCHART SYMBOLS

### **OVAL - Start/End**
```
 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
 ‚îÇ     ‚îÇ  Use for: Process start and end points
 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  Labels: "Start", "End", "Process Complete"
```
- **One start** per process
- **One or more ends** (including error exits)
- Clear entry and exit points

---

### **RECTANGLE - Process Step/Activity**
```
 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
 ‚îÇ  Action  ‚îÇ  Use for: Tasks, activities, operations
 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  Format: Action verb + object
```
**Examples:**
- "Review document"
- "Assemble parts"
- "Enter data"
- "Pack order"

**Best Practices:**
- One action per box
- Use specific verbs
- Keep concise (3-7 words)
- Consistent verb tense

---

### **DIAMOND - Decision/Question**
```
      ‚ï±‚ï≤
     ‚ï±  ‚ï≤     Use for: Yes/No questions, decision points
     ‚ï≤  ‚ï±     Format: Question with "?" 
      ‚ï≤‚ï±      Exits: Two paths (Yes/No or True/False)
```
**Examples:**
- "Approved?"
- "In stock?"
- "Complete?"
- "Pass inspection?"

**Best Practices:**
- Always phrase as yes/no question
- Label both exit paths clearly
- Only two exits per diamond

---

### **PARALLELOGRAM - Input/Output**
```
   ‚ï±‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï≤
  ‚ï±  I/O     ‚ï≤   Use for: Data or materials entering/leaving
  ‚ï≤          ‚ï±   Examples: Forms, reports, materials
   ‚ï≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï±
```
**Input Examples:**
- "Customer provides order"
- "Receive raw material"
- "Get approval form"

**Output Examples:**
- "Generate report"
- "Issue invoice"
- "Ship product"

---

### **ARROW - Flow Line**
```
  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí   Use for: Direction of flow
            Always show direction with arrowhead
```
**Conventions:**
- Flow top-to-bottom or left-to-right
- Can cross other arrows (minimize crossing)
- Label when helpful (especially decision exits: "Yes", "No")

---

### **CYLINDER - Database/Data Store**
```
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ      ‚îÇ   Use for: Database access, data storage
   ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ   Examples: System databases, file storage
```

---

### **DOCUMENT - Paper Document**
```
 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
 ‚îÇDocument‚îÇ   Use for: Physical documents, forms
 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚à©‚îÄ‚îÄ‚îÄ‚îò   Examples: Forms, printouts, reports
```

---

### **RECTANGLE WITH WAVY BASE - Stored Document**
```
 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
 ‚îÇ Filed  ‚îÇ   Use for: Filed/archived documents
 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚âà‚îÄ‚îÄ‚îÄ‚îò   Examples: Records, archived files
```

---

### **CONNECTOR - Same Page**
```
     ‚≠ï  Use for: Connecting separated parts of diagram
  Label with same letter/number on both connectors
```

---

### **OFF-PAGE CONNECTOR - Different Page**
```
   ‚îå‚îÄ‚îê
   ‚îÇ ‚îÇ   Use for: Continuation on another page
   ‚îî‚îÄ‚îò   Label with page reference
```

---

## VALUE STREAM MAPPING SYMBOLS

### **PROCESS BOX**
```
 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
 ‚îÇ   Process    ‚îÇ  Use for: Value-adding process steps
 ‚îÇ   Name       ‚îÇ  Include cycle time, uptime, etc.
 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```
**Typical metrics inside box:**
- C/T = Cycle Time (e.g., 45 seconds)
- C/O = Changeover Time (e.g., 30 minutes)
- Uptime = % (e.g., 85%)
- Batch Size (e.g., 50 units)
- # Operators (e.g., 2 people)

---

### **DATA BOX**
```
 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
 ‚îÇ  Process     ‚îÇ  
 ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  Attached below process box
 ‚îÇ  C/T: 45s   ‚îÇ  Shows process metrics
 ‚îÇ  Uptime: 85% ‚îÇ
 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### **INVENTORY TRIANGLE**
```
      ‚ñ≥     Use for: Inventory between processes
    ‚ñ≥ ‚ñ≥ ‚ñ≥   Label with quantity and days of supply
```
**Example:** 
- Label: "2,400 units"
- Days: "3 days"

---

### **PUSH ARROW**
```
  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ñ∂   Use for: Push production (not based on demand)
            Thick striped arrow
```

---

### **SUPERMARKET**
```
 ‚îå‚î¨‚î¨‚î¨‚î¨‚î¨‚îê
 ‚îî‚î¥‚î¥‚î¥‚î¥‚î¥‚îò   Use for: Controlled inventory (FIFO)
            Buffer for pull system
```

---

### **PULL ARROW**
```
  ‚áê‚ïê‚ïê‚ïê    Use for: Pull signal (demand-based)
           Thick arrow with fill
```

---

### **KANBAN CARD**
```
 ‚îå‚îÄ‚îÄ‚îê
 ‚îÇ‚ñ≠‚ñ≠‚îÇ   Use for: Kanban signal for replenishment
 ‚îî‚îÄ‚îÄ‚îò   Shows pull system in place
```

---

### **INFORMATION FLOW**
```
  ‚îÄ ‚îÄ ‚îÄ ‚ñ∂  Use for: Information (not material) flow
            Dashed line with arrow
```

---

### **MANUAL INFO**
```
     ‚úâ     Use for: Manual information (phone, paper)
```

---

### **ELECTRONIC INFO**
```
   ‚ö°‚ï±      Use for: Electronic information (email, system)
```

---

### **TIMELINE**
```
Processing Time:  ‚îÅ‚îÅ‚îÅ‚îÅ  (Value-added)
Wait Time:        ‚éØ ‚éØ ‚éØ  (Non-value-added)
```
**At bottom of VSM:**
- Top line: Value-added time for each step
- Bottom line: Wait/queue time between steps
- Total lead time = sum of both

---

## SWIMLANE DIAGRAM CONVENTIONS

### **Basic Structure**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ROLE/DEPARTMENT 1                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇAct1‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇAct2‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇAct3‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ROLE/DEPARTMENT 2                    ‚îÇ
‚îÇ       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ       ‚îÇAct4‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇAct5‚îÇ          ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Each lane represents:**
- Department
- Role
- System
- Person

**Arrows crossing lanes = Handoffs** (potential delays/errors)

---

## PROCESS MAPPING BEST PRACTICES

### **Level of Detail**

**Level 1 - SIPOC (5-8 steps)**
- High-level overview
- Major process phases only
- For initial understanding

**Level 2 - Process Map (10-30 steps)**
- Detailed steps within process
- Shows decision points
- For improvement analysis

**Level 3 - Procedure (30+ steps)**
- Very detailed instructions
- Every sub-step documented
- For training/SOPs

**Rule:** Start high-level, drill down only where needed!

---

### **Formatting Conventions**

‚úì **Consistent symbol size**
- All rectangles same size
- All diamonds same size
- Professional appearance

‚úì **Clear labels**
- Action verbs for activities
- Questions for decisions
- Concise wording

‚úì **Straight lines**
- Use alignment guides
- Minimize crossing
- Professional look

‚úì **Proper spacing**
- Equal spacing between symbols
- White space for readability
- Not too cramped

‚úì **Color coding (optional)**
- Value-added steps: Green
- Non-value-added: Yellow
- Waste: Red
- Helps visual analysis

---

### **Validation Checklist**

‚ñ° Start and end clearly marked  
‚ñ° All paths lead somewhere (no dead ends)  
‚ñ° Decision diamonds have two exits labeled  
‚ñ° Activities use action verbs  
‚ñ° Consistent symbol usage  
‚ñ° Symbols connected with arrows  
‚ñ° Flow direction clear  
‚ñ° Readable at normal zoom  
‚ñ° Legend included if non-standard symbols used

---

### **Common Mistakes to Avoid**

‚ùå Too much detail (can't see forest for trees)  
‚ùå Mixing levels (high-level and detailed in same map)  
‚ùå Missing decision points  
‚ùå Unlabeled arrows from decisions  
‚ùå Inconsistent symbols  
‚ùå Text too small to read  
‚ùå Mapping "should be" instead of "as is"

---

### **Software Tools**

**Free:**
- draw.io (Diagrams.net)
- Lucidchart (free tier)
- Google Drawings
- PowerPoint/Word (basic)

**Professional:**
- Microsoft Visio
- Lucidchart (full version)
- Miro
- MindManager
- SmartDraw

**VSM-Specific:**
- LeanKit
- VSM software tools
- Excel templates

---

## QUICK REFERENCE CARD

### **3 Most Used Symbols**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     Start/End
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   Activity
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

   ‚ï±‚ï≤
  ‚ï±  ‚ï≤        Decision
  ‚ï≤  ‚ï±
   ‚ï≤‚ï±
```

### **Flow Direction**
```
Top ‚Üí Bottom  OR  Left ‚Üí Right
(Pick one and stay consistent!)
```

### **Decision Exits**
```
      ‚ï±‚ï≤
 Yes ‚ï±  ‚ï≤ No
    ‚ï±    ‚ï≤
```

---

**Remember:** The best process map is one that communicates clearly to your audience. Use standard symbols, keep it simple, and validate with people who do the work!

---

## Document Information

**Total Guides:** 6  
**Coverage:** All Foundation Belt tools and techniques  
**Format:** Print-ready, laminate-able reference cards  
**Version:** 1.0  
**Last Updated:** October 3, 2025  
**Maintained By:** CI Master Academy

---

**Printing Recommendations:**
- Standard size: 8.5" √ó 11" (full page)
- Card size: 4" √ó 6" (scaled down)
- Paper: Heavy cardstock (110 lb)
- Lamination: 3-5 mil thickness
- Color: Full color for maximum usability
- Binding: Ring binding for multi-card sets

**Digital Use:**
- Save as PDF for easy sharing
- Bookmark sections for quick navigation
- Use on tablets during Gemba walks
- Project during training sessions

---

*These quick reference guides are part of the CI Master Academy Foundation Belt (White Belt) curriculum and designed for daily use by continuous improvement practitioners.*
